{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717983db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b8f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보안 감시 가동 중... (종료하려면 Q를 누르세요)\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n",
      "경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m보안 감시 가동 중... (종료하려면 Q를 누르세요)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# 속도 향상을 위한 그레이스케일 변환\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import ctypes\n",
    "import os\n",
    "\n",
    "# 1. 얼굴 인식 모델 (가장 가벼운 Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 2. 웹캠 연결\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 속도 최적화를 위한 웹캠 해상도 하향 설정 (선택 사항)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "def hide_windows():\n",
    "    # Windows + D 효과를 내는 쉘 명령 (가장 빠름)\n",
    "    ctypes.windll.shell32.ShellExecuteW(None, \"open\", \"shell:::{30805640-F057-11D2-9D73-0000F81EF32E}\", None, None, 1)\n",
    "\n",
    "print(\"보안 감시 가동 중... (종료하려면 Q를 누르세요)\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # 속도 향상을 위한 그레이스케일 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 얼굴 감지 (minNeighbors 값을 높이면 오작동은 줄어들지만 감지 속도에 영향을 줍니다)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        print(\"경고: 얼굴 감지됨! 바탕화면으로 전환합니다.\")\n",
    "        hide_windows()\n",
    "        # 한 번 실행 후 무한 반복 방지를 위해 감시 잠시 중단 (필요시 조정)\n",
    "        cv2.waitKey(2000) \n",
    "\n",
    "    # 실시간 확인이 필요 없다면 아래 창 출력 부분은 주석 처리 시 속도가 더 빨라집니다.\n",
    "    # cv2.imshow('Security Monitor', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "# model_selection=1 은 2m 밖의 먼 거리 얼굴에 최적화된 모델입니다.\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # MediaPipe는 RGB 이미지를 사용합니다.\n",
    "    results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.detections:\n",
    "        print(\"멀리 있는 인물 감지!\")\n",
    "        pyautogui.hotkey('win', 'd')\n",
    "        time.sleep(5)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad719f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import time\n",
    "import ctypes\n",
    "\n",
    "pyautogui.FAILSAFE = False\n",
    "pyautogui.PAUSE = 0\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# L-shape ROI based on your latest arrow image (normalized x, y)\n",
    "# Tune these points if camera angle changes.\n",
    "VERTICAL_ROI_NORM = np.array([\n",
    "    [0.11, 0.04],\n",
    "    [0.34, 0.04],\n",
    "    [0.34, 1.00],\n",
    "    [0.11, 1.00],\n",
    "], dtype=np.float32)\n",
    "\n",
    "HORIZONTAL_ROI_NORM = np.array([\n",
    "    [0.32, 0.20],\n",
    "    [0.79, 0.20],\n",
    "    [0.79, 0.43],\n",
    "    [0.32, 0.43],\n",
    "], dtype=np.float32)\n",
    "\n",
    "CAMERA_INDEX_CANDIDATES = (0, 1, 2)\n",
    "CAMERA_RESOLUTION_CANDIDATES = ((1280, 720), (960, 540), (640, 480))\n",
    "DETECT_MIN_SIZE = (12, 12)\n",
    "DETECT_MIN_NEIGHBORS = 2\n",
    "DETECT_SCALE_FACTOR = 1.03\n",
    "UPSCALE_FACTOR = 1.8\n",
    "UPSCALED_MIN_SIZE = (18, 18)\n",
    "\n",
    "BACKENDS = []\n",
    "if hasattr(cv2, \"CAP_MSMF\"):\n",
    "    BACKENDS.append((\"MSMF\", cv2.CAP_MSMF))\n",
    "if hasattr(cv2, \"CAP_DSHOW\"):\n",
    "    BACKENDS.append((\"DSHOW\", cv2.CAP_DSHOW))\n",
    "BACKENDS.append((\"ANY\", cv2.CAP_ANY))\n",
    "\n",
    "def to_pixels(points_norm, frame_w, frame_h):\n",
    "    pts = points_norm.copy()\n",
    "    pts[:, 0] *= frame_w\n",
    "    pts[:, 1] *= frame_h\n",
    "    return pts.astype(np.int32)\n",
    "\n",
    "def get_roi_polygons(frame_w, frame_h):\n",
    "    return [\n",
    "        to_pixels(VERTICAL_ROI_NORM, frame_w, frame_h),\n",
    "        to_pixels(HORIZONTAL_ROI_NORM, frame_w, frame_h),\n",
    "    ]\n",
    "\n",
    "def build_roi_mask(frame_h, frame_w, polygons):\n",
    "    mask = np.zeros((frame_h, frame_w), dtype=np.uint8)\n",
    "    for poly in polygons:\n",
    "        cv2.fillPoly(mask, [poly], 255)\n",
    "    return mask\n",
    "\n",
    "def box_iou(a, b):\n",
    "    ax1, ay1, aw, ah = a\n",
    "    bx1, by1, bw, bh = b\n",
    "    ax2, ay2 = ax1 + aw, ay1 + ah\n",
    "    bx2, by2 = bx1 + bw, by1 + bh\n",
    "\n",
    "    inter_x1 = max(ax1, bx1)\n",
    "    inter_y1 = max(ay1, by1)\n",
    "    inter_x2 = min(ax2, bx2)\n",
    "    inter_y2 = min(ay2, by2)\n",
    "\n",
    "    if inter_x2 <= inter_x1 or inter_y2 <= inter_y1:\n",
    "        return 0.0\n",
    "\n",
    "    inter = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)\n",
    "    union = (aw * ah) + (bw * bh) - inter\n",
    "    if union <= 0:\n",
    "        return 0.0\n",
    "    return inter / union\n",
    "\n",
    "def nms(boxes, iou_threshold=0.25):\n",
    "    if not boxes:\n",
    "        return []\n",
    "\n",
    "    boxes = sorted(boxes, key=lambda b: b[2] * b[3], reverse=True)\n",
    "    kept = []\n",
    "    for box in boxes:\n",
    "        if all(box_iou(box, k) < iou_threshold for k in kept):\n",
    "            kept.append(box)\n",
    "    return kept\n",
    "\n",
    "def test_camera_stream(cap, tries=20, min_success=3):\n",
    "    success = 0\n",
    "    for _ in range(tries):\n",
    "        ok, _ = cap.read()\n",
    "        if ok:\n",
    "            success += 1\n",
    "            if success >= min_success:\n",
    "                return True\n",
    "        time.sleep(0.01)\n",
    "    return False\n",
    "\n",
    "def open_camera(preferred_index=None):\n",
    "    index_order = list(CAMERA_INDEX_CANDIDATES)\n",
    "    if preferred_index in index_order:\n",
    "        index_order.remove(preferred_index)\n",
    "        index_order.insert(0, preferred_index)\n",
    "\n",
    "    for idx in index_order:\n",
    "        for backend_name, backend in BACKENDS:\n",
    "            for width, height in CAMERA_RESOLUTION_CANDIDATES:\n",
    "                cap = cv2.VideoCapture(idx, backend)\n",
    "                if not cap.isOpened():\n",
    "                    cap.release()\n",
    "                    continue\n",
    "\n",
    "                cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "                cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "                if hasattr(cv2, \"CAP_PROP_BUFFERSIZE\"):\n",
    "                    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "                fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "                cap.set(cv2.CAP_PROP_FOURCC, fourcc)\n",
    "\n",
    "                if test_camera_stream(cap):\n",
    "                    print(f\"[INFO] Camera opened (index={idx}, backend={backend_name}, size={width}x{height})\")\n",
    "                    return cap, idx\n",
    "\n",
    "                cap.release()\n",
    "    return None\n",
    "\n",
    "def minimize_desktop():\n",
    "    try:\n",
    "        pyautogui.hotkey(\"win\", \"d\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            user32 = ctypes.windll.user32\n",
    "            key_up = 0x0002\n",
    "            vk_lwin = 0x5B\n",
    "            vk_d = 0x44\n",
    "            user32.keybd_event(vk_lwin, 0, 0, 0)\n",
    "            user32.keybd_event(vk_d, 0, 0, 0)\n",
    "            user32.keybd_event(vk_d, 0, key_up, 0)\n",
    "            user32.keybd_event(vk_lwin, 0, key_up, 0)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "def detect_faces(gray, polygons, roi_mask):\n",
    "    all_boxes = []\n",
    "\n",
    "    for poly in polygons:\n",
    "        rx, ry, rw, rh = cv2.boundingRect(poly)\n",
    "        if rw < 10 or rh < 10:\n",
    "            continue\n",
    "\n",
    "        roi_gray = gray[ry:ry + rh, rx:rx + rw]\n",
    "        roi_mask_patch = roi_mask[ry:ry + rh, rx:rx + rw]\n",
    "        roi_gray = cv2.bitwise_and(roi_gray, roi_gray, mask=roi_mask_patch)\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            roi_gray,\n",
    "            scaleFactor=DETECT_SCALE_FACTOR,\n",
    "            minNeighbors=DETECT_MIN_NEIGHBORS,\n",
    "            minSize=DETECT_MIN_SIZE,\n",
    "        )\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            all_boxes.append((x + rx, y + ry, w, h))\n",
    "\n",
    "        up = cv2.resize(roi_gray, None, fx=UPSCALE_FACTOR, fy=UPSCALE_FACTOR, interpolation=cv2.INTER_LINEAR)\n",
    "        up_faces = face_cascade.detectMultiScale(\n",
    "            up,\n",
    "            scaleFactor=DETECT_SCALE_FACTOR,\n",
    "            minNeighbors=DETECT_MIN_NEIGHBORS,\n",
    "            minSize=UPSCALED_MIN_SIZE,\n",
    "        )\n",
    "\n",
    "        for (x, y, w, h) in up_faces:\n",
    "            ox = int(x / UPSCALE_FACTOR) + rx\n",
    "            oy = int(y / UPSCALE_FACTOR) + ry\n",
    "            ow = int(w / UPSCALE_FACTOR)\n",
    "            oh = int(h / UPSCALE_FACTOR)\n",
    "            all_boxes.append((ox, oy, ow, oh))\n",
    "\n",
    "    merged = nms(all_boxes, iou_threshold=0.25)\n",
    "    faces_in_roi = []\n",
    "    for (x, y, w, h) in merged:\n",
    "        cx = x + w // 2\n",
    "        cy = y + h // 2\n",
    "        for poly in polygons:\n",
    "            if cv2.pointPolygonTest(poly, (float(cx), float(cy)), False) >= 0:\n",
    "                faces_in_roi.append((x, y, w, h))\n",
    "                break\n",
    "\n",
    "    return faces_in_roi\n",
    "\n",
    "opened = open_camera()\n",
    "if opened is None:\n",
    "    raise RuntimeError(\"Camera open failed. Close other apps using webcam and run again.\")\n",
    "\n",
    "cap, current_cam_index = opened\n",
    "print(\"보안 감시 가동 중... (Q를 누르면 종료)\")\n",
    "\n",
    "last_action_time = 0.0\n",
    "cooldown_sec = 5\n",
    "read_fail_count = 0\n",
    "reconnect_attempts = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        read_fail_count += 1\n",
    "        if read_fail_count % 20 == 0:\n",
    "            print(f\"[WARN] Frame read failed x{read_fail_count}\")\n",
    "\n",
    "        if read_fail_count >= 20:\n",
    "            reconnect_attempts += 1\n",
    "            print(f\"[WARN] Attempting camera reconnect #{reconnect_attempts}...\")\n",
    "            cap.release()\n",
    "            reopened = open_camera(preferred_index=current_cam_index)\n",
    "            if reopened is not None:\n",
    "                cap, current_cam_index = reopened\n",
    "                read_fail_count = 0\n",
    "                print(\"[INFO] Camera stream recovered\")\n",
    "                continue\n",
    "\n",
    "            if reconnect_attempts >= 10:\n",
    "                print(\"[ERROR] Camera stream could not be recovered. Exiting loop.\")\n",
    "                break\n",
    "\n",
    "            read_fail_count = 0\n",
    "\n",
    "        time.sleep(0.05)\n",
    "        continue\n",
    "\n",
    "    read_fail_count = 0\n",
    "    reconnect_attempts = 0\n",
    "\n",
    "    frame_h, frame_w = frame.shape[:2]\n",
    "    polygons = get_roi_polygons(frame_w, frame_h)\n",
    "    roi_mask = build_roi_mask(frame_h, frame_w, polygons)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    faces_in_roi = detect_faces(gray, polygons, roi_mask)\n",
    "\n",
    "    now = time.time()\n",
    "    if len(faces_in_roi) > 0 and (now - last_action_time) >= cooldown_sec:\n",
    "        print(f\"!!! Face detected in ROI ({len(faces_in_roi)}) !!!\")\n",
    "        if minimize_desktop():\n",
    "            print(\"[ACTION] Win+D executed\")\n",
    "        else:\n",
    "            print(\"[ERROR] Failed to execute Win+D\")\n",
    "        last_action_time = now\n",
    "\n",
    "    overlay = frame.copy()\n",
    "    for poly in polygons:\n",
    "        cv2.fillPoly(overlay, [poly], (40, 70, 140))\n",
    "    frame = cv2.addWeighted(overlay, 0.18, frame, 0.82, 0)\n",
    "\n",
    "    for poly in polygons:\n",
    "        cv2.polylines(frame, [poly], True, (255, 220, 0), 2)\n",
    "    for (x, y, w, h) in faces_in_roi:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Security Monitor\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "security_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
